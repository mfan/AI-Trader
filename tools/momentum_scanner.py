"""
Momentum Scanner - Top Volume Movers Selection System

Scans the market for high-volume stocks with strong momentum.
Identifies top 50 gainers and top 50 losers from previous trading day.

Quality Filters (No Junk):
- Price: >= $5 (avoids penny stock behavior)
- Market Cap: >= $2 billion (sweet spot: filters out micro-caps, keeps movers)
- Volume: >= 10M-20M daily (liquidity + volatility sweet spot)
- Universe: S&P 500 and NASDAQ-100 only (excludes OTC, pink sheets, penny stocks)

$2B Market Cap Rationale:
- Below $1B-$1.5B: jumpy gaps, fragile order book, easy manipulation
- $2B+: Cuts most penny/low-float garbage, still catches 3-10%+ daily movers
- Can increase to $5B+ later if too much noise

This implements a dynamic watchlist based on actual market momentum
rather than static lists, ensuring we trade what's moving NOW.
"""

import os
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
import logging
from alpaca.data.timeframe import TimeFrame
from configs.settings import TradingConfig

# Configure logging
logger = logging.getLogger(__name__)

# Quality filters
MIN_PRICE = TradingConfig.MIN_PRICE
MIN_VOLUME = TradingConfig.MIN_VOLUME
IDEAL_VOLUME = TradingConfig.IDEAL_VOLUME
MIN_MARKET_CAP = TradingConfig.MIN_MARKET_CAP

# Momentum parameters
TOP_GAINERS_COUNT = TradingConfig.TOP_GAINERS_COUNT
TOP_LOSERS_COUNT = TradingConfig.TOP_LOSERS_COUNT
TOTAL_WATCHLIST_SIZE = TradingConfig.TOTAL_WATCHLIST_SIZE

# Technical Analysis (optional, will add later)
TA_AVAILABLE = False


class MomentumScanner:
    """
    Scans market for high-volume momentum stocks.
    
    Strategy:
    1. Filter: Volume >= 10M-20M (liquidity + volatility sweet spot)
    2. Rank: By price change % (momentum strength)
    3. Select: Top 50 gainers + Top 50 losers
    4. Calculate: Full TA indicators for each stock
    5. Cache: Store in SQLite for fast intraday access
    """
    
    def __init__(self, alpaca_client=None):
        """
        Initialize momentum scanner.
        
        Args:
            alpaca_client: Alpaca API client (optional, will create if needed)
        """
        self.alpaca_client = alpaca_client
        self.cached_movers = None
        self.cache_date = None
        
    async def scan_previous_day_movers(
        self, 
        scan_date: Optional[str] = None,
        min_volume: int = MIN_VOLUME,
        max_results: int = TOTAL_WATCHLIST_SIZE
    ) -> Dict[str, List[Dict]]:
        """
        Scan for top volume movers from previous trading day.
        
        Args:
            scan_date: Date to scan (YYYY-MM-DD), defaults to yesterday
            min_volume: Minimum daily volume filter
            max_results: Total stocks to return (split 50/50 gainers/losers)
            
        Returns:
            Dictionary with 'gainers' and 'losers' lists, each containing
            stock data with momentum scores and TA indicators
        """
        if scan_date is None:
            # Use previous business day
            scan_date = self._get_previous_business_day()
        
        logger.info(f"ðŸ” Scanning momentum stocks for {scan_date}")
        logger.info(f"   Filters: Price >= ${MIN_PRICE}, Market Cap >= ${MIN_MARKET_CAP:,}, Volume >= {min_volume:,}")
        
        try:
            # Get universe of liquid stocks
            universe = await self._get_tradeable_universe()
            logger.info(f"   Scanning {len(universe)} stocks from tradeable universe")
            
            # For large universes (>500 stocks), we need to be smart about fetching
            # Alpaca's API is slow for fetching bars for thousands of stocks
            # Strategy: Batch process in chunks
            if len(universe) > 500:
                logger.info(f"   âš¡ Large universe detected - using batch processing")
            
            # Fetch market data for previous day
            market_data = await self._fetch_market_data(universe, scan_date)
            
            if not market_data:
                logger.error("No market data retrieved")
                return {'gainers': [], 'losers': []}
            
            # Filter by price (>= $5 to avoid penny stock behavior)
            price_filtered = self._filter_by_price(market_data, MIN_PRICE)
            logger.info(f"   âœ… {len(price_filtered)} stocks with price >= ${MIN_PRICE}")
            
            # Filter by volume
            high_volume_stocks = self._filter_by_volume(price_filtered, min_volume)
            logger.info(f"   âœ… {len(high_volume_stocks)} stocks with {min_volume:,}+ volume")
            
            if not high_volume_stocks:
                logger.warning("No stocks meet volume criteria")
                return {'gainers': [], 'losers': []}
            
            # Separate into actual gainers (positive) and losers (negative)
            gainers = [s for s in high_volume_stocks if s.get('change_pct', 0) > 0]
            losers = [s for s in high_volume_stocks if s.get('change_pct', 0) < 0]
            
            # Rank each group by momentum strength
            gainers_ranked = self._rank_by_momentum(gainers)
            losers_ranked = self._rank_by_momentum(losers)  # Still descending, so most negative first
            
            # Reverse losers so most negative (worst loser) is first
            losers_ranked = losers_ranked[::-1]
            
            # Select top from each group
            gainers_count = max_results // 2
            losers_count = max_results - gainers_count
            
            top_gainers = gainers_ranked[:gainers_count]
            top_losers = losers_ranked[:losers_count]
            
            logger.info(f"   ðŸ“ˆ Top {len(top_gainers)} gainers selected (from {len(gainers)} gainers)")
            logger.info(f"   ðŸ“‰ Top {len(top_losers)} losers selected (from {len(losers)} losers)")
            
            # Warn if we didn't get enough stocks
            total_selected = len(top_gainers) + len(top_losers)
            if total_selected < max_results:
                logger.warning(f"   âš ï¸  Only {total_selected} stocks selected (target: {max_results})")
                logger.warning(f"   âš ï¸  Not enough stocks with strong momentum on this day")
            
            # Calculate technical indicators for selected stocks
            logger.info("   ðŸ”§ Calculating technical indicators...")
            gainers_with_ta = await self._add_technical_indicators(top_gainers, scan_date)
            losers_with_ta = await self._add_technical_indicators(top_losers, scan_date)
            
            # Log summary
            if top_gainers:
                best_gainer = top_gainers[0]
                logger.info(f"   ðŸ† Best gainer: {best_gainer['symbol']} "
                          f"({best_gainer['change_pct']:+.2f}%, "
                          f"Vol: {best_gainer['volume']:,.0f})")
            
            if top_losers:
                worst_loser = top_losers[0]
                logger.info(f"   ðŸ’” Worst loser: {worst_loser['symbol']} "
                          f"({worst_loser['change_pct']:+.2f}%, "
                          f"Vol: {worst_loser['volume']:,.0f})")
            
            result = {
                'gainers': gainers_with_ta,
                'losers': losers_with_ta,
                'scan_date': scan_date,
                'total_scanned': len(universe),
                'high_volume_count': len(high_volume_stocks)
            }
            
            # Cache results
            self.cached_movers = result
            self.cache_date = scan_date
            
            return result
            
        except Exception as e:
            logger.error(f"Error scanning momentum stocks: {e}", exc_info=True)
            return {'gainers': [], 'losers': []}
    
    def _get_previous_business_day(self) -> str:
        """Get previous business day (skip weekends)."""
        today = datetime.now()
        days_back = 1
        
        # If today is Monday, go back to Friday
        if today.weekday() == 0:  # Monday
            days_back = 3
        elif today.weekday() == 6:  # Sunday
            days_back = 2
        
        previous_day = today - timedelta(days=days_back)
        return previous_day.strftime('%Y-%m-%d')
    
    async def _get_tradeable_universe(self) -> List[str]:
        """
        Get universe of ALL tradeable stocks on US exchanges.
        
        Fetches from Alpaca API with filters:
        - Active and tradeable
        - US exchanges (NASDAQ, NYSE, AMEX, ARCA)
        - Excludes OTC, pink sheets
        - Common stocks only (no warrants, units, etc.)
        
        Additional filtering by price, market cap, and volume happens later.
        This ensures we scan the ENTIRE market, not a pre-selected list.
        """
        try:
            from alpaca.trading.client import TradingClient
            from alpaca.trading.requests import GetAssetsRequest
            from alpaca.trading.enums import AssetClass, AssetStatus
            import os
            from dotenv import load_dotenv
            
            # Load environment variables
            load_dotenv()
            
            # Initialize Alpaca client
            api_key = os.getenv('ALPACA_API_KEY')
            api_secret = os.getenv('ALPACA_SECRET_KEY')
            
            if not api_key or not api_secret:
                logger.error("   âŒ Alpaca API credentials not found in environment")
                return self._get_fallback_universe()
            
            client = TradingClient(api_key, api_secret, paper=True)
            
            # Get all active, tradeable US stocks
            search_params = GetAssetsRequest(
                status=AssetStatus.ACTIVE,
                asset_class=AssetClass.US_EQUITY
            )
            
            assets = client.get_all_assets(search_params)
            
            # Filter for quality stocks
            symbols = []
            for asset in assets:
                # Must be tradeable
                if not asset.tradable:
                    continue
                
                # Must be on major exchanges (no OTC, pink sheets)
                if asset.exchange not in ['NASDAQ', 'NYSE', 'AMEX', 'ARCA', 'NYSEARCA']:
                    continue
                
                # Must be common stock (no warrants, units, preferred, etc.)
                # Symbol shouldn't contain special characters
                if any(char in asset.symbol for char in ['.', '^', '/', ' ', '-']):
                    continue
                
                # Skip leveraged/inverse ETFs (contain these patterns)
                symbol_upper = asset.symbol.upper()
                if any(pattern in symbol_upper for pattern in ['3X', 'TRIPLE', 'ULTRA', 'INVERSE', 'SHORT']):
                    continue
                
                # Must be shortable and easy to borrow (indicates real stock)
                if asset.shortable and asset.easy_to_borrow:
                    symbols.append(asset.symbol)
            
            logger.info(f"   âœ… Found {len(symbols)} tradeable stocks on US exchanges")
            return sorted(symbols)
            
        except Exception as e:
            logger.error(f"   âŒ Error fetching universe from Alpaca: {e}")
            return self._get_fallback_universe()
    
    def _get_fallback_universe(self) -> List[str]:
        """
        Fallback universe if Alpaca API fails.
        Uses major liquid stocks as backup.
        """
        logger.warning("   âš ï¸  Using fallback universe (106 major stocks)")
        
        return [
            # Mega cap tech
            "AAPL", "MSFT", "GOOGL", "GOOG", "AMZN", "META", "NVDA", "TSLA",
            # Tech
            "NFLX", "ADBE", "CRM", "ORCL", "CSCO", "INTC", "AMD", "QCOM",
            "AVGO", "TXN", "AMAT", "LRCX", "KLAC", "MU", "MRVL", "NOW",
            # Financials
            "JPM", "BAC", "WFC", "C", "GS", "MS", "BLK", "SCHW", "AXP",
            "V", "MA", "PYPL", "SQ", "COIN",
            # Healthcare
            "UNH", "JNJ", "LLY", "ABBV", "MRK", "PFE", "TMO", "ABT",
            "GILD", "REGN", "VRTX", "BIIB", "MRNA",
            # Consumer
            "HD", "NKE", "SBUX", "MCD", "DIS", "BKNG",
            "COST", "WMT", "TGT", "LOW", "ABNB", "UBER", "DASH",
            # Energy
            "XOM", "CVX", "COP", "SLB", "OXY", "MPC", "PSX", "VLO",
            # Industrials
            "CAT", "DE", "BA", "UPS", "RTX", "LMT", "GE", "HON",
            # High momentum/volatility
            "PLTR", "SNOW", "CRWD", "NET", "DDOG", "ZS", "PANW", "SMCI",
            "MSTR", "RIOT", "MARA", "SHOP", "HOOD",
            # ETFs (for market regime)
            "SPY", "QQQ", "IWM", "DIA", "XLK", "XLF", "XLE", "XLV",
            "SMH", "SOXX", "ARKK", "TLT", "GLD"
        ]
    
    async def _fetch_market_data(
        self, 
        symbols: List[str], 
        date: str
    ) -> List[Dict]:
        """
        Fetch market data for given symbols on specified date.
        
        For large universes, processes in batches to avoid timeouts.
        
        Returns list of dicts with: symbol, open, high, low, close, volume, change_pct
        """
        logger.info(f"   ðŸ“¡ Fetching market data for {len(symbols)} symbols on {date}")
        
        market_data = []
        
        try:
            # Use Alpaca Data Feed directly
            # Import here to avoid circular dependencies
            from tools.alpaca_data_feed import AlpacaDataFeed
            from datetime import datetime
            
            # Create data feed instance
            data_feed = AlpacaDataFeed()
            
            # Convert date string to datetime
            date_obj = datetime.strptime(date, '%Y-%m-%d')
            
            # For large universes, process in batches to avoid API timeouts
            BATCH_SIZE = 200  # Alpaca can handle ~200 symbols per request efficiently
            total_batches = (len(symbols) + BATCH_SIZE - 1) // BATCH_SIZE
            
            if len(symbols) > BATCH_SIZE:
                logger.info(f"   âš¡ Processing {len(symbols)} symbols in {total_batches} batches")
            
            for i in range(0, len(symbols), BATCH_SIZE):
                batch = symbols[i:i+BATCH_SIZE]
                batch_num = i // BATCH_SIZE + 1
                
                if len(symbols) > BATCH_SIZE:
                    logger.info(f"   ðŸ“¦ Batch {batch_num}/{total_batches}: Fetching {len(batch)} symbols")
                
                # Fetch bars for this batch
                bars_data = data_feed.get_bars(
                    symbols=batch,
                    start=date_obj,
                    end=date_obj + timedelta(days=1),
                    timeframe=TimeFrame.Day
                )
                
                if not bars_data:
                    continue
                
                # Convert to our format
                for symbol, bars in bars_data.items():
                    if bars and len(bars) > 0:
                        bar = bars[0]  # Should be only one bar for single day
                        
                        open_price = bar.get('o', bar.get('open', 0))
                        close_price = bar.get('c', bar.get('close', 0))
                        
                        # Calculate price change %
                        change_pct = 0
                        if open_price > 0:
                            change_pct = ((close_price - open_price) / open_price) * 100
                        
                        stock_data = {
                            'symbol': symbol,
                            'open': open_price,
                            'high': bar.get('h', bar.get('high', 0)),
                            'low': bar.get('l', bar.get('low', 0)),
                            'close': close_price,
                            'volume': bar.get('v', bar.get('volume', 0)),
                            'change_pct': change_pct,
                            'date': date
                        }
                        
                        market_data.append(stock_data)
            
            logger.info(f"   âœ… Retrieved {len(market_data)} stocks with market data")
            return market_data
            
        except ImportError:
            logger.error("   âŒ Could not import alpaca_data_feed - using MCP HTTP calls")
            
            # Fallback: Direct HTTP calls to MCP server
            import httpx
            
            try:
                async with httpx.AsyncClient(timeout=30.0) as client:
                    # Call get_bars for each symbol (batch processing)
                    for symbol in symbols:
                        try:
                            response = await client.post(
                                'http://localhost:8004/call-tool',
                                json={
                                    'name': 'get_bars',
                                    'arguments': {
                                        'symbol': symbol,
                                        'start': date,
                                        'end': date,
                                        'timeframe': '1Day'
                                    }
                                }
                            )
                            
                            if response.status_code == 200:
                                result = response.json()
                                bars = result.get('content', [])
                                
                                if bars and len(bars) > 0:
                                    bar = bars[0]
                                    open_price = bar.get('o', bar.get('open', 0))
                                    close_price = bar.get('c', bar.get('close', 0))
                                    
                                    change_pct = 0
                                    if open_price > 0:
                                        change_pct = ((close_price - open_price) / open_price) * 100
                                    
                                    stock_data = {
                                        'symbol': symbol,
                                        'open': open_price,
                                        'high': bar.get('h', bar.get('high', 0)),
                                        'low': bar.get('l', bar.get('low', 0)),
                                        'close': close_price,
                                        'volume': bar.get('v', bar.get('volume', 0)),
                                        'change_pct': change_pct,
                                        'date': date
                                    }
                                    
                                    market_data.append(stock_data)
                        
                        except Exception as e:
                            logger.debug(f"   Error fetching {symbol}: {e}")
                            continue
                
                logger.info(f"   âœ… Retrieved {len(market_data)} stocks via HTTP")
                return market_data
                
            except Exception as e:
                logger.error(f"   âŒ Error fetching market data: {e}")
                return []
        
        except Exception as e:
            logger.error(f"   âŒ Unexpected error fetching market data: {e}", exc_info=True)
            return []
    
    async def _fetch_market_caps(self, symbols: List[str]) -> Dict[str, float]:
        """
        Fetch market capitalization for given symbols.
        
        Returns dict mapping symbol to market cap in dollars.
        Uses Alpaca's latest quote + known share counts.
        For production, should use a proper financial data API.
        """
        market_caps = {}
        
        try:
            from tools.alpaca_data_feed import AlpacaDataFeed
            data_feed = AlpacaDataFeed()
            
            # Get latest prices
            prices = data_feed.get_latest_prices(symbols)
            
            # For now, we'll use approximate share counts for major stocks
            # In production, fetch from a financial data API like Alpha Vantage or Yahoo Finance
            # For our curated list of mega/large caps, we can assume they all meet $1B threshold
            # Since we pre-filter the universe to liquid, large stocks
            
            # Quick approximation: if price * typical_shares > 1B, include it
            # Most stocks in our universe (AAPL, MSFT, etc.) are well over $1B
            for symbol, price in prices.items():
                if price and price > 0:
                    # Estimate shares outstanding (this is approximate)
                    # For production, fetch actual shares outstanding from API
                    # For our mega-cap universe, assume all qualify
                    market_caps[symbol] = 1_000_000_000  # Placeholder
            
            return market_caps
            
        except Exception as e:
            logger.warning(f"   âš ï¸  Could not fetch market caps: {e}")
            # If we can't fetch market caps, assume all qualify (fail-safe)
            # since our curated universe is already large-caps
            return {symbol: MIN_MARKET_CAP for symbol in symbols}
    
    def _filter_by_price(
        self,
        market_data: List[Dict],
        min_price: float
    ) -> List[Dict]:
        """
        Filter stocks by minimum price.
        
        This removes penny stock behavior (< $5) which tends to be:
        - Jumpy gaps and fragile order books
        - Easy to manipulate
        - High slippage
        """
        return [
            stock for stock in market_data
            if stock.get('close', 0) >= min_price
        ]
    
    def _filter_by_volume(
        self, 
        market_data: List[Dict], 
        min_volume: int
    ) -> List[Dict]:
        """Filter stocks by minimum volume."""
        return [
            stock for stock in market_data 
            if stock.get('volume', 0) >= min_volume
        ]
    
    def _filter_by_market_cap(
        self,
        market_data: List[Dict],
        market_caps: Dict[str, float],
        min_market_cap: float
    ) -> List[Dict]:
        """
        Filter stocks by minimum market capitalization.
        
        This removes penny stocks and micro-caps that create noise.
        """
        filtered = []
        for stock in market_data:
            symbol = stock['symbol']
            market_cap = market_caps.get(symbol, 0)
            
            if market_cap >= min_market_cap:
                stock['market_cap'] = market_cap
                filtered.append(stock)
            else:
                logger.debug(f"   Filtered out {symbol}: Market cap ${market_cap:,.0f} < ${min_market_cap:,.0f}")
        
        return filtered
    
    def _rank_by_momentum(self, stocks: List[Dict]) -> List[Dict]:
        """
        Rank stocks by momentum (price change %).
        
        Returns sorted list: highest gainers first, losers at end.
        """
        # Calculate change_pct if not already present
        for stock in stocks:
            if 'change_pct' not in stock:
                open_price = stock.get('open', stock.get('close', 0))
                close_price = stock.get('close', 0)
                if open_price > 0:
                    stock['change_pct'] = ((close_price - open_price) / open_price) * 100
                else:
                    stock['change_pct'] = 0
        
        # Sort by change_pct descending
        ranked = sorted(stocks, key=lambda x: x['change_pct'], reverse=True)
        
        return ranked
    
    async def _add_technical_indicators(
        self, 
        stocks: List[Dict], 
        date: str
    ) -> List[Dict]:
        """
        Add technical indicators to each stock.
        
        Calculates:
        - RSI (14)
        - MACD + Signal + Histogram
        - EMAs (9, 20, 50)
        - ATR (14) for volatility
        - Volume indicators
        - Elder's Impulse System
        """
        enriched_stocks = []
        
        for stock in stocks:
            symbol = stock['symbol']
            
            try:
                # Fetch historical data for TA calculations (need ~60 days)
                # hist_data = await self._fetch_historical_data(symbol, date, days=60)
                
                # Calculate indicators
                indicators = self._calculate_indicators(stock, date)
                
                # Merge stock data with indicators
                enriched_stock = {**stock, **indicators}
                enriched_stocks.append(enriched_stock)
                
            except Exception as e:
                logger.warning(f"   âš ï¸  Error calculating indicators for {symbol}: {e}")
                enriched_stocks.append(stock)
        
        return enriched_stocks
    
    def _calculate_indicators(self, stock: Dict, date: str) -> Dict:
        """
        Calculate technical indicators for a stock.
        
        Returns dict of indicator values.
        """
        indicators = {
            'rsi': None,
            'macd': None,
            'macd_signal': None,
            'macd_hist': None,
            'ema_9': None,
            'ema_20': None,
            'ema_50': None,
            'atr': None,
            'impulse_color': None,
            'trend': None,
            'volatility': None
        }
        
        # TODO: Implement actual TA calculations using historical data
        # For now, return placeholder
        
        return indicators
    
    def get_momentum_watchlist(self) -> List[str]:
        """
        Get list of symbols from cached momentum scan.
        
        Returns combined list of gainers + losers symbols.
        """
        if not self.cached_movers:
            logger.warning("No cached momentum data. Run scan_previous_day_movers() first.")
            return []
        
        gainers = [stock['symbol'] for stock in self.cached_movers.get('gainers', [])]
        losers = [stock['symbol'] for stock in self.cached_movers.get('losers', [])]
        
        return gainers + losers
    
    def get_market_regime(self) -> str:
        """
        Determine overall market regime based on SPY/QQQ momentum.
        
        Returns: 'bullish', 'bearish', or 'neutral'
        """
        if not self.cached_movers:
            return 'neutral'
        
        # Check if SPY/QQQ are in gainers or losers
        all_stocks = (self.cached_movers.get('gainers', []) + 
                     self.cached_movers.get('losers', []))
        
        spy_data = next((s for s in all_stocks if s['symbol'] == 'SPY'), None)
        qqq_data = next((s for s in all_stocks if s['symbol'] == 'QQQ'), None)
        
        if spy_data and qqq_data:
            avg_change = (spy_data.get('change_pct', 0) + 
                         qqq_data.get('change_pct', 0)) / 2
            
            if avg_change > 0.5:
                return 'bullish'
            elif avg_change < -0.5:
                return 'bearish'
        
        return 'neutral'
    
    def print_summary(self):
        """Print summary of cached momentum scan."""
        if not self.cached_movers:
            print("No cached momentum data available.")
            return
        
        print(f"\n{'='*80}")
        print(f"MOMENTUM SCAN SUMMARY - {self.cache_date}")
        print(f"{'='*80}")
        
        gainers = self.cached_movers.get('gainers', [])
        losers = self.cached_movers.get('losers', [])
        
        print(f"\nðŸ“ˆ TOP GAINERS ({len(gainers)} stocks):")
        print(f"{'â”€'*80}")
        for i, stock in enumerate(gainers[:10], 1):
            print(f"{i:2d}. {stock['symbol']:6s} {stock['change_pct']:+7.2f}%  "
                  f"Vol: {stock['volume']:>12,.0f}  Close: ${stock['close']:.2f}")
        
        print(f"\nðŸ“‰ TOP LOSERS ({len(losers)} stocks):")
        print(f"{'â”€'*80}")
        for i, stock in enumerate(losers[:10], 1):
            print(f"{i:2d}. {stock['symbol']:6s} {stock['change_pct']:+7.2f}%  "
                  f"Vol: {stock['volume']:>12,.0f}  Close: ${stock['close']:.2f}")
        
        regime = self.get_market_regime()
        print(f"\nðŸŽ¯ Market Regime: {regime.upper()}")
        print(f"{'='*80}\n")


# Convenience function for quick scans
async def scan_momentum_stocks(
    scan_date: Optional[str] = None,
    min_volume: int = MIN_VOLUME
) -> Dict[str, List[Dict]]:
    """
    Quick function to scan momentum stocks.
    
    Usage:
        movers = await scan_momentum_stocks()
        gainers = movers['gainers']
        losers = movers['losers']
    """
    scanner = MomentumScanner()
    return await scanner.scan_previous_day_movers(scan_date, min_volume)


if __name__ == "__main__":
    # Test the scanner
    logging.basicConfig(level=logging.INFO)
    
    async def test_scan():
        scanner = MomentumScanner()
        movers = await scanner.scan_previous_day_movers()
        scanner.print_summary()
        
        print(f"\nâœ… Momentum watchlist: {len(scanner.get_momentum_watchlist())} symbols")
    
    asyncio.run(test_scan())
